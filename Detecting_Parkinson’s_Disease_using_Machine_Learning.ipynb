{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSrwXRaF4GyTHi1E3uW/2H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashSingh23/Detecting-Parkinson-s-Disease-using-Machine-Learning/blob/main/Detecting_Parkinson%E2%80%99s_Disease_using_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lzrftmFVwHW4"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os # Used for file system operations, though less critical if directly uploading\n",
        "import sys # Used for system-specific parameters and functions, not directly used in this script for core logic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "V9chJCJAwvkr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Data Loading ---\n",
        "# DataFlair - Read the data\n",
        "# Make sure 'parkinsons.data' is uploaded to your Colab session or downloaded using Kaggle API\n",
        "# If you uploaded it, it will be in the /content/ directory by default.\n",
        "try:\n",
        "    df = pd.read_csv('parkinsons.data')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'parkinsons.data' not found. Please upload the file or use the Kaggle API to download it.\")\n",
        "    print(\"You can upload it via the 'Files' tab on the left sidebar in Colab.\")\n",
        "    # Exit or handle the error appropriately if the file is crucial\n",
        "    sys.exit(1) # Exit the script if the file is not found\n",
        "\n",
        "# Display the first 5 records to verify\n",
        "print(\"\\nFirst 5 records of the dataset:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtUgHnOhw2M7",
        "outputId": "57753c66-c3a5-4047-cbba-897d1310157b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "\n",
            "First 5 records of the dataset:\n",
            "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
            "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
            "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
            "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
            "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
            "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
            "\n",
            "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
            "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
            "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
            "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
            "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
            "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
            "\n",
            "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
            "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
            "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
            "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
            "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
            "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
            "\n",
            "    spread2        D2       PPE  \n",
            "0  0.266482  2.301442  0.284654  \n",
            "1  0.335590  2.486855  0.368674  \n",
            "2  0.311173  2.342259  0.332634  \n",
            "3  0.334147  2.405554  0.368975  \n",
            "4  0.234513  2.332180  0.410335  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Feature and Label Extraction ---\n",
        "# DataFlair - Get the features and labels\n",
        "# Features are all columns except 'status', labels are the 'status' column\n",
        "# The original instruction says .values[:,1:] which implies skipping the first column (name)\n",
        "features = df.loc[:, df.columns != 'status'].values[:, 1:]\n",
        "labels = df.loc[:, 'status'].values\n",
        "\n",
        "print(\"\\nFeatures shape:\", features.shape)\n",
        "print(\"Labels shape:\", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIOH9PrVw87M",
        "outputId": "7c3c0b5f-b665-4579-90ec-1578e4680112"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features shape: (195, 22)\n",
            "Labels shape: (195,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Label Distribution Check ---\n",
        "# DataFlair - Get the count of each label (0 and 1) in labels\n",
        "count_ones = labels[labels == 1].shape[0]\n",
        "count_zeros = labels[labels == 0].shape[0]\n",
        "print(f\"\\nNumber of samples with Parkinson's (status=1): {count_ones}\")\n",
        "print(f\"Number of samples without Parkinson's (status=0): {count_zeros}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SggzYnDQxAx5",
        "outputId": "f0f9bca1-4d45-492e-f809-dc15724ecf2f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of samples with Parkinson's (status=1): 147\n",
            "Number of samples without Parkinson's (status=0): 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Feature Scaling ---\n",
        "# DataFlair - Scale the features to between -1 and 1\n",
        "# Initialize MinMaxScaler to scale features between -1 and 1\n",
        "scaler = MinMaxScaler((-1, 1))\n",
        "# Apply the scaler to the features\n",
        "x = scaler.fit_transform(features)\n",
        "# Labels (y) do not need scaling\n",
        "y = labels\n",
        "\n",
        "print(\"\\nFeatures after scaling (first 5 rows):\")\n",
        "print(x[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwWYqWYwxEd_",
        "outputId": "22caa6d9-05e1-4753-c711-6b19f6fc49ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features after scaling (first 5 rows):\n",
            "[[-0.63138346 -0.77481654 -0.89037042 -0.60864041 -0.50197628 -0.70905588\n",
            "  -0.50482315 -0.70942366 -0.37557057 -0.43960559 -0.33474576 -0.30529172\n",
            "  -0.65510376 -0.33483117 -0.86338606  0.02349021 -0.26168916  0.92029673\n",
            "   0.13975042  0.17153026 -0.21867743 -0.0053808 ]\n",
            " [-0.6033463  -0.81013911 -0.4433544  -0.49174079 -0.4229249  -0.61753372\n",
            "  -0.35262594 -0.6179162  -0.05422677 -0.11092851  0.03197227  0.07137042\n",
            "  -0.4411517   0.03209655 -0.88133813 -0.13484516 -0.05833903  0.95404891\n",
            "   0.40655399  0.48267409 -0.05370956  0.34265204]\n",
            " [-0.66992292 -0.88174367 -0.46942324 -0.43964422 -0.34387352 -0.54142582\n",
            "  -0.26152197 -0.54117836 -0.21873288 -0.34757601 -0.11325116 -0.10773406\n",
            "  -0.56030324 -0.113365   -0.92080721 -0.00755913 -0.19116806  1.\n",
            "   0.2734894   0.37274182 -0.18236124  0.19336492]\n",
            " [-0.66999278 -0.85414536 -0.47159948 -0.47331639 -0.34387352 -0.58188825\n",
            "  -0.35048232 -0.58227645 -0.17144422 -0.29005752 -0.04892142 -0.06784261\n",
            "  -0.53242974 -0.04904352 -0.91800618 -0.0081281  -0.16748993  0.95177008\n",
            "   0.391255    0.47617729 -0.12604566  0.34389886]\n",
            " [-0.67770067 -0.83818243 -0.47978629 -0.2909784  -0.18577075 -0.4344894\n",
            "  -0.12540193 -0.43425911 -0.00109549 -0.1799507   0.16910632  0.15468114\n",
            "  -0.42629604  0.16908461 -0.89165102 -0.08900268 -0.24968209  0.98562584\n",
            "   0.52494407  0.02759675 -0.19132885  0.51522281]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Dataset Splitting ---\n",
        "# DataFlair - Split the dataset into training and testing sets\n",
        "# 80% for training, 20% for testing\n",
        "# random_state ensures reproducibility of the split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7)\n",
        "\n",
        "print(f\"\\nTraining features shape: {x_train.shape}\")\n",
        "print(f\"Testing features shape: {x_test.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Testing labels shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dR_cn3VxIqB",
        "outputId": "35b0f3ad-0b10-41d9-c9c1-f970fd959b43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training features shape: (156, 22)\n",
            "Testing features shape: (39, 22)\n",
            "Training labels shape: (156,)\n",
            "Testing labels shape: (39,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Model Training ---\n",
        "# DataFlair - Train the model\n",
        "# Initialize the XGBClassifier model\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss') # Suppress warning by setting use_label_encoder and eval_metric\n",
        "# Train the model using the training data\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "print(\"\\nXGBoost model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iX_URmCxM9i",
        "outputId": "50db9e88-4068-4440-e255-7adde79ec218"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [19:31:33] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "XGBoost model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7: Prediction and Accuracy Calculation ---\n",
        "# DataFlair - Calculate the accuracy\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "# Calculate the accuracy score and convert to percentage\n",
        "accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "\n",
        "print(f\"\\nModel Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RMHtgYixQfT",
        "outputId": "a086619c-cc0c-4514-de32-93b1d501e83d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy: 94.87%\n"
          ]
        }
      ]
    }
  ]
}